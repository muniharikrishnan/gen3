{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl7BZutBYGhn",
        "outputId": "ba6af581-fc66-445e-b7ab-ce18d6ed4efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in output_audio.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Building video no_audio.mp4.\n",
            "Moviepy - Writing video no_audio.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  99%|█████████▉| 1559/1569 [00:09<00:00, 117.69it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/videoplayback (11).mp4, 388800 bytes wanted but 0 bytes read,at frame 1567/1569, at time 52.23/52.29 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/videoplayback (11).mp4, 388800 bytes wanted but 0 bytes read,at frame 1568/1569, at time 52.27/52.29 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready no_audio.mp4\n",
            "original_language:english\n",
            "translated_languagetelungu\n",
            "always right cleaner code don't use a cells in a method like this instead you can use a dictionary how to use a dictionary check this out we can simply copy a dictionary here with the wheels data by default this function is returning zero let us keep it there but if the dictionary is present if the value is present inside the dictionary so if we can in Wheels data, only then return Wheels data and use vehicle as the key okay let me just run it and be successfully actually replaced if else conditions with the cleaner version of this code see you in the next video\n",
            "ఎల్లప్పుడూ కుడి క్లీనర్ కోడ్ ఇలాంటి పద్ధతిలో సెల్‌లను ఉపయోగించవద్దు బదులుగా మీరు నిఘంటువుని ఎలా ఉపయోగించాలో డిక్షనరీని ఉపయోగించవచ్చు దీన్ని తనిఖీ చేయండి మేము డిఫాల్ట్‌గా చక్రాల డేటాతో డిక్షనరీని ఇక్కడ కాపీ చేయవచ్చు ఈ ఫంక్షన్ సున్నాని తిరిగి ఇస్తుందిడిక్షనరీ ఉంది కానీ డిక్షనరీ లోపల విలువ ఉన్నట్లయితే, వీల్స్ డేటాలో మనం చేయగలిగితే, వీల్స్ డేటాను తిరిగి ఇవ్వండి మరియు వాహనాన్ని కీగా ఉపయోగించుకోండి సరే, నేను దానిని అమలు చేయనివ్వండి మరియు వాస్తవానికి దాన్ని విజయవంతంగా భర్తీ చేయనివ్వండిఈ కోడ్ యొక్క క్లీనర్ వెర్షన్ మిమ్మల్ని తదుపరి వీడియోలో కలుద్దాం\n",
            "Moviepy - Building video synced_video.mp4.\n",
            "MoviePy - Writing audio in synced_videoTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video synced_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready synced_video.mp4\n",
            "yes or noyes\n",
            "enter the command:generate the text of the video\n",
            "audio_language:telungu\n",
            "ఆల్వేస్ రైట్ క్లీనర్ కోడ్ డోంట్ యూస్ ఎఫెక్ట్స్ ఇన్ ద మెథడ్ లైక్ డేస్ ఎస్టేట్ యు కెన్ యు ద డిక్షనరీ హౌ టు యూస్ డిక్షనరీ చెక్ ది సౌత్ వీకెండ్ సింప్లీ కాపీ డిక్షనరీ విత్ ద వీల్ స్టేటస్ వేల్యూ ఇస్ ప్రెసెంట్ ఇన్ సైడ్ ఇన్ వీల్స్ డేటా, ఓన్లీ దెన్ రిటర్న్ విల్\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!apt install ffmpeg\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install gtts\n",
        "!pip install nltk\n",
        "!pip install moviepy\n",
        "\n",
        "\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from googletrans import Translator\n",
        "from gtts import gTTS\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "nltk.download('punkt')\n",
        "\n",
        "#extract the audio from the video\n",
        "# Import the necessary module\n",
        "from moviepy.editor import *\n",
        "\n",
        "# Load the video\n",
        "video = VideoFileClip(\"/content/videoplayback (11).mp4\")\n",
        "\n",
        "# Extract audio\n",
        "audio = video.audio\n",
        "\n",
        "# Save the audio\n",
        "audio.write_audiofile(\"output_audio.mp3\")\n",
        "\n",
        "#remove the audio from the video\n",
        "\n",
        "# Import necessary libraries\n",
        "\n",
        "# Use moviepy to remove audio from the video\n",
        "\n",
        "clip = video\n",
        "video_only = clip.without_audio()\n",
        "output_video_path = \"no_audio.mp4\" # replace with desired output path\n",
        "video_only.write_videofile(output_video_path)\n",
        "\n",
        "#export the mp3 format to wav format\n",
        "from pydub import AudioSegment\n",
        "\n",
        "audio = AudioSegment.from_mp3(\"output_audio.mp3\")\n",
        "audio.export(\"output_audio.wav4\", format=\"wav\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_tamil():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='ta').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"ta\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "    #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_english_to_hindi():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='hi').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"hi\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_hindi_to_tamil():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='hi-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='hi', dest='ta').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(translated_text,lang=\"ta\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "\n",
        "\n",
        "     #sync the audio into the video\n",
        "    from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_hindi_to_english():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='hi-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='hi', dest='en').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"en\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_tamil_to_english():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ta-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='ta', dest='en').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"en\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "def generate_audio_from_tamil_to_hindi():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ta-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='ta', dest='hi').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"en\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "\n",
        "def generate_english_text():\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_hindi_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='hi-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "def generate_tamil_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ta-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_malayalam():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='ml').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"ml\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_kannadam():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='kn').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"kn\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_telungu():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='te').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"te\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_english_to_bengali():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='bn').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"bn\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_punjabi():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='pa').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"pa\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_gujarati():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='gu').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"gu\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_audio_from_english_to_urdu():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='ur').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"ur\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "\n",
        "\n",
        "def generate_audio_from_english_to_sanskrit():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='en-US')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "\n",
        "\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(final_text, src='en', dest='sa').text\n",
        "    print(translated_text)\n",
        "\n",
        "    tts= gTTS(text=translated_text,lang=\"sa\")\n",
        "    tts.save(\"new_audio.mp3\")\n",
        "\n",
        "     #sync the audio into the video\n",
        "\n",
        "    def sync_audio_to_video(audio_path, empty_video_path, output_video_path):\n",
        "    # Load audio and video clips\n",
        "        audio_clip = AudioFileClip(audio_path)\n",
        "        empty_video_clip = VideoFileClip(empty_video_path)\n",
        "\n",
        "        # Set the audio of the empty video to the extracted audio\n",
        "        synced_video_clip = empty_video_clip.set_audio(audio_clip)\n",
        "\n",
        "        # Write the synchronized video to the output path\n",
        "        synced_video_clip.write_videofile(output_video_path, codec=\"libx264\")\n",
        "\n",
        "\n",
        "    audio_path = \"new_audio.mp3\"\n",
        "    empty_video_path = \"no_audio.mp4\"\n",
        "    output_video_path = \"synced_video.mp4\"\n",
        "\n",
        "    sync_audio_to_video(audio_path, empty_video_path, output_video_path)\n",
        "\n",
        "def generate_malayalam_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ml-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_kannadam_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='kn-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_telungu_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='te-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_urdu_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ur-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_punjabi_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='pa-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "def generate_gujarati_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='gu-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_urdu_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='ur-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_sanskrit_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='sa-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "def generate_bengali_text():\n",
        "\n",
        "\n",
        "    # Initialize the recognizer\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Load the audio and split it into 30-second chunks\n",
        "    audio = AudioSegment.from_wav(\"output_audio.wav4\")\n",
        "    chunk_length = 30 * 1000  # 30 seconds in milliseconds\n",
        "    chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
        "\n",
        "    # Define function to process audio chunk\n",
        "    def process_audio_chunk(chunk):\n",
        "       # Save the chunk to a temporary file\n",
        "       chunk_filename = \"temp_chunk.wav\"\n",
        "       chunk.export(chunk_filename, format=\"wav\")\n",
        "\n",
        "       # Convert audio chunk to text\n",
        "       with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_data = recognizer.record(source)\n",
        "            try:\n",
        "                text = recognizer.recognize_google(audio_data, language='bn-IN')\n",
        "\n",
        "                # Use Sentence Boundary Detection\n",
        "                sentences = sent_tokenize(text)\n",
        "\n",
        "                # Combine sentences with commas\n",
        "                return \", \".join(sentences)\n",
        "            except:\n",
        "                return \"\"\n",
        "\n",
        "    # Process each chunk\n",
        "    texts = [process_audio_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine all texts\n",
        "    final_text = \", \".join(texts)\n",
        "    print(final_text)\n",
        "\n",
        "\n",
        "\n",
        "def generate_audio():\n",
        "  # Load the video\n",
        "  videos = video\n",
        "\n",
        "  # Extract audio\n",
        "  audios = videos.audio\n",
        "\n",
        "  # Save the audio\n",
        "  audios.write_audiofile(\"output_audio.mp3\")\n",
        "\n",
        "\n",
        "\n",
        "def adoptive_learning():\n",
        "  command=input(\"enter the command:\")\n",
        "  if command==\"generate the text of the video\":\n",
        "     def generate_text():\n",
        "       audio_language=input(\"audio_language:\")\n",
        "       if audio_language==\"english\":\n",
        "         generate_english_text()\n",
        "       if audio_language==\"tamil\":\n",
        "         generate_tamil_text()\n",
        "       if audio_language==\"hindi\":\n",
        "         generate_hindi_text()\n",
        "       if audio_language==\"telungu\":\n",
        "         generate_telungu_text()\n",
        "       if audio_language==\"kannadam\":\n",
        "         generate_kannadam_text()\n",
        "       if audio_language==\"malayalam\":\n",
        "         generate_malayalam_text()\n",
        "       if audio_language==\"gujarati\":\n",
        "         generate_gujarati_text()\n",
        "       if audio_language==\"urdu\":\n",
        "         generate_urdu_text()\n",
        "       if audio_language==\"bengali\":\n",
        "         generate_bengali_text()\n",
        "       if audio_language==\"punjabi\":\n",
        "         generate_punjabi_text()\n",
        "       if audio_language==\"sanskrit\":\n",
        "         generate_sanskrit_text()\n",
        "\n",
        "\n",
        "     generate_text()\n",
        "\n",
        "\n",
        "original_language = input(\"original_language:\")\n",
        "translated_language = input(\"translated_language\")\n",
        "if original_language=='tamil'and translated_language==\"english\":\n",
        "  generate_audio_from_tamil_to_english()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='tamil'and translated_language=='hindi':\n",
        "  generate_audio_from_tamil_to_hindi()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='tamil':\n",
        "  generate_audio_from_english_to_tamil()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='hindi':\n",
        "  generate_audio_from_english_to_hindi()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='hindi'and translated_language=='tamil':\n",
        "  generate_audio_from_hindi_to_tamil()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='hindi'and translated_language=='english':\n",
        "  generate_audio_from_hindi_to_english()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language==(\"tamil\" or \"english\" or \"hindi\") and translated_language==\"no\":\n",
        "    generate_audio()\n",
        "    adoptive_learning()\n",
        "\n",
        "\n",
        "if original_language=='english'and translated_language=='malayalam':\n",
        "  generate_audio_from_english_to_malayalam()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='kannadam':\n",
        "  generate_audio_from_english_to_kannadam()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='telungu':\n",
        "  generate_audio_from_english_to_telungu()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='gujarti':\n",
        "  generate_audio_from_english_to_gujarati()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='punjabi':\n",
        "  generate_audio_from_english_to_punjabi()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='sanskrit':\n",
        "  generate_audio_from_english_to_sanskrit()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='urdu':\n",
        "  generate_audio_from_english_to_urdu()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n",
        "\n",
        "if original_language=='english'and translated_language=='bengali':\n",
        "  generate_audio_from_english_to_bengali()\n",
        "  adoptivelearning=input(\"yes or no\")\n",
        "  if adoptivelearning==\"yes\":\n",
        "    adoptive_learning()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hIHdxLgYATDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}